---
# Global variables, which can be inherited in blocks
pc_creds: &pc_creds
  # This can be admin/ ad user. Note ad creds will be used after adding AD to PC
  pc_username: pc-user
  pc_password: pc-password
  # New admin password for PC
  admin_pc_password: admin-pc-password

ncm_creds: &ncm_creds
  ncm_username: pc-user
  ncm_password: pc-password
  # New admin password for NCM
  admin_ncm_password: admin-ncm-password 

pe_creds: &pe_creds
    # This can be admin/ ad user. Note ad creds will be used after adding AD to PE
  pe_username: pe-user
  pe_password: pe-password
  # New admin password for PE
  admin_pe_password: admin-pe-password

# Block level re-usable configurations in clusters, can be placed within blocks if block level configurations are
# different
ad_config: &ad_config
  directory_services:
    directory_type: ACTIVE_DIRECTORY # only ACTIVE_DIRECTORY is supported, port 389 will be used for LDAP
    ad_name: name
    ad_domain: eng.company.com
    ad_server_ip: valid-ip
    service_account_username: username
    service_account_password: password
    role_mappings:
      - role_type: ROLE_USER_ADMIN # one of 'ROLE_CLUSTER_ADMIN', 'ROLE_USER_ADMIN', 'ROLE_CLUSTER_VIEWER', 'ROLE_BACKUP_ADMIN'
        entity_type: GROUP # one of GROUP, OU, USER
        values:
          - john_doe
          - john_smith

cluster_eula: &eula
  eula:
    username: Nutanix
    company_name: Nutanix
    job_title: Backend Engineer

pulse: &pulse
  enable_pulse: true

pe_container: &pe_container
  name: Automation-container
  # All these below parameters are optional
  #storage_pool_uuid: uuid # Which storage pool to use, comment it to auto pick storage pool
  reserved_in_gb: 1 # Represents the minimum exclusively reserved storage capacity available for the storage container
  advertisedCapacity_in_gb: 1 # Represents the maximum storage capacity available for the storage container to use
  replication_factor: 2 # Number of data copies to maintain
  compression_enabled: true # Only Inline compression is supported yet
  compression_delay_in_secs: 0
  erasure_code: "OFF" # OFF/ ON # Erasure code requires a minimum of 4 nodes when using RF2 and a minimum of 6 nodes when using RF3
  on_disk_dedup: "OFF" # OFF/ ON # Deduplication is not supported with fewer than 3 nodes
  nfsWhitelistAddress: [ ] # Access list for storage container

pe_networks: &pe_networks
  name: "vlan-110"
  subnet_type: VLAN # only VLAN is supported yet
  vlan_id: 110
  network_ip: valid-ip
  network_prefix: 24
  default_gateway_ip: valid-ip
  # virtual_switch: "vs0" # Optional. If not specified, the first virtual switch will be used
  # comment pool_list section if there are no pools for the subnet
  pool_list:
    - range: "valid-ip-start valid-ip-end" # Eg "10.10.10.31 10.10.10.40"
  #  comment dhcp_options section if you don't want dhcp. Over-riding dhcp is not supported yet
  dhcp_options:
    domain_name_server_list: [ 10.10.10.10 ]
    domain_search_list: [ eng.company.com ]
    domain_name: eng.company.com

ncm_subnets: &ncm_subnets
  ncm_subnets:
    - vlan-110

ncm_users: &ncm_users
  ncm_users:
    - user1@domain
    - user2@domain

name_servers: &name_servers
  name_servers_list:
    - valid-name-server1
    - valid-name-server1

ntp_servers: &ntp_servers
  ntp_servers_list:
    - 0.us.pool.ntp.org
    - 1.us.pool.ntp.org
    - 2.us.pool.ntp.org

# A single pod can support up to 2,000 edge clusters
pod:
  pod_name: pod-1
  pod_blocks:
    # Each block can support a maximum of 400 edge locations
    - pod_block_name: block-01
      pc_ip: valid-block-pc-ip
      # Using globally declared pc credentials
      <<: *pc_creds
      # Use global eula config
      <<: *eula
      # Use global pulse config
      <<: *pulse
      # Use global ad config
      <<: *ad_config
      # global NTP, DNS servers
      <<: *ntp_servers
      <<: *name_servers

      # NCM VM IP
      ncm_vm_ip: valid-calm-ip
      # Using globally declared ncm credentials
      <<: *ncm_creds
      ncm_account:
        # Only nuatnix_pc is supported yet
        name: PC1
        sync_interval_seconds: !!int 900
        # if type == nutanix_pc fill in below details. Below are optional
        pc_ip: block-pc-ip
        <<: *pc_creds

      objects:
        objectstores:
          - name: objectstore01
            domain: eng.company.com
            cluster: cluster-01
            # DHCP subnet
            network: vlan110
            # 4 statis IPs
            static_ip_list:
             - ip1
             - ip2
             - ip3
             - ip4
            num_worker_nodes: 1
            buckets:
              - name: bucket1
                user_access_list:
                  - darshan@domain
                  - kousalya@domain

        # Use global ad config for directory services
        directory_services:
          - <<: *directory_services

      remote_azs:
        # remote AZ details, only Physical location is supported yet
        valid-remote-pc-ip:
          username: remote-pc-user
          password: remote-pc-password

      # To create categories in current PC
      categories:
        # Scenario 1, add values to an existing category
        - name: AppType # name of existing category
          description: "AppType CalmAppliance"
          values: [ "CalmAppliance" ]
        # Scenario 2, create a new category with values
        - name: AZ01-DR-01
          description: "AZ01-DR-01 RPO1h"
          values: [ "RPO1h" ]

      # Only three-node clusters at edge locations replicate data to the primary regional BCDR clusters
      # To create protection policies in current PC. Note, if it's already created in remote AZ, you don't have to create again
      protection_rules:
        - name: AZ01-AZ02-Calm
          desc: "Example Protection Rule for CalmAppliance"
          protected_categories:
            AppType:
              - CalmAppliance
          schedules:
            - source:
                # Source should always be Local AZ i.e local block PC
                availability_zone: valid-local-block-pc-ip
                clusters:
                  - source-cluster1 # regional BCDR cluster1
                  - source-cluster2 # regional BCDR cluster2
              destination:
                availability_zone: valid-local-block-pc-ip/valid-remote-pc-ip
                cluster: destination-cluster
              protection_type: ASYNC # ASYNC/ SYNC
              # if protection_type is SYNC
              #auto_suspend_timeout: 10
              # if protection_type is ASYNC
              rpo: 1
              rpo_unit: HOUR # MINUTE/HOUR/DAY/WEEK
              snapshot_type: "CRASH_CONSISTENT" # APPLICATION_CONSISTENT/CRASH_CONSISTENT
              local_retention_policy:
                # For Linear Retention type (Retains the n most recent snapshots. A value of 12 means that the 12 most recent snapshots are retained)
                num_snapshots: 1
                # For Roll-up retention type (Maintains a rolling window of snapshots for every schedule, starting with the hourly schedule and ending with the schedule created for the specified retention period)
                #rollup_retention_policy:
                #snapshot_interval_type: YEARLY # DAILY/WEEKLY/MONTHLY/YEARLY
                #multiple: 2
              remote_retention_policy:
                # For Linear Retention type
                num_snapshots: 1
                # For Roll-up retention type
                #rollup_retention_policy:
                #snapshot_interval_type: YEARLY # HOURLY/DAILY/WEEKLY/MONTHLY/YEARLY
                #multiple: 2

      # To create recovery plans in current PC. Note, if it's already created in remote AZ, you don't have to create again
      recovery_plans:
        - name: AZ01-RP-Calm
          desc: "Example Recovery plan for AppType CalmAppliance"
          primary_location:
            # Primary location is set to Local block/ AZ
            availability_zone: valid-local-block-pc-ip
            # cluster: bucky01-dev # Optional. Required only for Local AZ to Local AZ
          recovery_location:
            availability_zone: valid-remote-pc-ip
            # cluster: bucky02-dev # Optional. Required only for Local AZ to Local AZ
          stages:
            #- vms:
            #- name: ubuntu-01
            #enable_script_exec: true
            #delay: 2
            - categories:
                - key: AppType
                  value: CalmAppliance
          network_type: NON_STRETCH # NON_STRETCH/STRETCH
          network_mappings:
            - primary:
                test:
                  name: valid-subnet-name
                  #gateway_ip: gateway_ip Optional
                  #prefix: network_prefix
                prod:
                  name: valid-subnet-name
                  #gateway_ip: gateway_ip
                  #prefix: network_prefix
              recovery:
                test:
                  name: valid-subnet-name
                  #gateway_ip: gateway_ip
                  #prefix: network_prefix
                prod:
                  name: valid-subnet-name
                  #gateway_ip: gateway_ip
                  #prefix: network_prefix

      # To create Address Groups in current PC
      address_groups:
        - name: AD
          description: "Example AD Address Groups"
          subnets:
            - network_ip: valid-ip # Eg: 10.10.10.130
              network_prefix: valid-prefix # Eg: 32
        - name: Calm
          description: "Example Calm Address Groups"
          subnets:
            - network_ip: valid-ip # Eg: 10.10.10.130
              network_prefix: valid-prefix # Eg: 32

      # To create Service Groups in current PC
      service_groups:
        - name: ngt
          description: Example Service Group NGT - TCP
          service_details:
            tcp:
              - "2074"
        - name: dns
          description: Example Service Group DNS - UDP
          service_details:
            udp:
              - "53"

      # To create Flow Security Policies in current PC
      security_policies:
        - name: Example-AZ01-Calm
          description: Example Security Policy
          allow_ipv6_traffic: true # true/ false # Policy rules apply only to IPv4 Traffic and all IPv6 traffic are blocked by default.
          hitlog: true # true/ false # Log traffic flow hits on the policy rules
          # Only app rules are supported for now
          app_rule:
            policy_mode: MONITOR # APPLY/MONITOR
            # Secure this app
            target_group:
              categories:
                AppType: AZ01LAMP01
            inbounds:
              - categories:
                  AppTier:
                    - WEB
                address:
                  name: Calm
                protocol:
                  service:
                    name: ssh
              - categories:
                  AppTier:
                    - APP
                udp:
                  - start_port: 82
                    end_port: 8080
                address:
                  name: Calm
                protocol:
                  service:
                    name: ssh
              - categories:
                  AppTier:
                    - DB
                address:
                  name: Calm
                protocol:
                  service:
                    name: ssh
            outbounds:
              - address:
                  name: NVD_AD
                protocol:
                  service:
                    name: dns

      # Configure edge-clusters managed by this block
      # Each block can support a maximum of 400 edge clusters
      edge_sites:
        - site_name: site-01
          clusters:
            # configure the below clusters in the site
            valid-site01-cluster-01-ip:
              name: cluster-01 # Optional if name is already provided above
              # Use global pe creds
              <<: *pe_creds
              # Use global eula config
              <<: *eula
              # Use global pulse config
              <<: *pulse
              # Use global ad config
              <<: *ad_config
              dsip: valid-ip
              networks:
                # Use global network config
                - <<: *pe_networks
              containers:
                # Use global storage container config
                - <<: *pe_container

              # The subnets, users that need to be added to NCM project that are created for every cluster
              <<: *ncm_subnets
              <<: *ncm_users

              # NTP, DNS servers
              <<: *ntp_servers
              <<: *name_servers
            valid-site02-cluster-02-ip:
              name: cluster-02 # Optional if name is already provided above
              # Use global pe creds
              <<: *pe_creds
              # Over-ride global eula config
              eula:
                username: username
                company_name: Nutanix
                job_title: title
              # Use global pulse config
              <<: *pulse
              # Over-ride global ad config
              directory_services:
                directory_type: ACTIVE_DIRECTORY # only ACTIVE_DIRECTORY is supported, port 389 will be used for LDAP
                ad_name: some-other-name
                ad_domain: eng.company.com
                ad_server_ip: valid-ip
                service_account_username: username
                service_account_password: password
                role_mappings:
                  - role_type: ROLE_USER_ADMIN # one of 'ROLE_CLUSTER_ADMIN', 'ROLE_USER_ADMIN', 'ROLE_CLUSTER_VIEWER', 'ROLE_BACKUP_ADMIN'
                    entity_type: GROUP # one of GROUP, OU, USER
                    values:
                      - yash
                      - naveen
              dsip: valid-ip
              networks:
                # Use global network config and add another network
                - <<: *pe_networks
                - name: "vlan-200"
                  subnet_type: VLAN # only VLAN is supported yet
                  vlan_id: 200
                  network_ip: valid-ip
                  network_prefix: 24
                  default_gateway_ip: valid-ip
                  # comment pool_list section if there are no pools for the subnet
                  pool_list:
                    - range: "valid-ip-start valid-ip-end" # Eg "10.10.10.31 10.10.10.40"
                  #  comment dhcp_options section if you don't want dhcp. Over-riding dhcp is not supported yet
                  dhcp_options:
                    domain_name_server_list: [ 10.10.10.10 ]
                    domain_search_list: [ eng.company.com ]
                    domain_name: eng.company.com
              containers:
                # Use global storage container config and add another container
                - <<: *pe_container
                - name: Automation-container-2
                  # All these below parameters are optional
                  #storage_pool_uuid: uuid # Which storage pool to use, comment it to auto pick storage pool
                  reserved_in_gb: 1 # Represents the minimum exclusively reserved storage capacity available for the storage container
                  advertisedCapacity_in_gb: 1 # Represents the maximum storage capacity available for the storage container to use
                  replication_factor: 2 # Number of data copies to maintain
                  compression_enabled: true # Only Inline compression is supported yet
                  compression_delay_in_secs: 0
                  erasure_code: "OFF" # OFF/ ON # Erasure code requires a minimum of 4 nodes when using RF2 and a minimum of 6 nodes when using RF3
                  on_disk_dedup: "OFF" # OFF/ ON # Deduplication is not supported with fewer than 3 nodes
                  nfsWhitelistAddress: [ ] # Access list for storage container

              # The subnets, users that need to be added to NCM project that are created for every cluster
              <<: *ncm_subnets
              <<: *ncm_users

              # NTP, DNS servers
              <<: *ntp_servers
              <<: *name_servers
          nke_clusters:
            # configure the below nke_clusters in the site
            - cluster:
                name: cluster-01
              name: valid-name
              cluster_type: DEV # DEV/ PROD
              k8s_version: 1.19.8-0
              host_os: ntnx-1.0
              node_subnet:
                name: vlan110 # valid IPAM
              cni:
                node_cidr_mask_size: 24
                service_ipv4_cidr: "172.19.0.0/16"
                pod_ipv4_cidr: "172.20.0.0/16"
                network_provider: Calico # Calico/ Flannel
              custom_node_configs:
                etcd:
                  num_instances: 1 # 1 for DEV, 3 for PROD
                  cpu: 4
                  memory_gb: 8
                  disk_gb: 40
                masters:
                  num_instances: 1 # 1 for DEV, 2 for PROD
                  cpu: 2 # 2 for DEV, 4 for PROD
                  memory_gb: 4 # 4 for DEV, 8 for PROD
                  disk_gb: 120
                workers:
                  num_instances: 1 # 1 for DEV, 3 for PROD
                  cpu: 8
                  memory_gb: 8
                  disk_gb: 120
              storage_class:
                # Credentials of the PE where you've selected the storage container from
                <<: *pe_creds
                default_storage_class: True
                name: default-storageclass
                reclaim_policy: Retain # "Retain"/ "Delete"
                storage_container: default-container-78262 #Storage container to use in the cluster defined above
                file_system: ext4 # "ext4"/ "xfs"
                flash_mode: false # true/ false
        - site_name: site-02
          clusters:
            # configure the below clusters in the site
            valid-site02-cluster-01-ip:
              name: cluster-01 # Optional if name is already provided above
              # Use global pe creds
              <<: *pe_creds
              # Use global eula config
              <<: *eula
              # Use global pulse config
              <<: *pulse
              # Use global ad config
              <<: *ad_config
              dsip: valid-ip
              networks:
                # Use global network config
                - <<: *pe_networks
              containers:
                # Use global storage container config
                - <<: *pe_container

              # The subnets, users that need to be added to NCM project that are created for every cluster
              <<: *ncm_subnets
              <<: *ncm_users
            valid-site02-cluster-02-ip:
              name: cluster-02 # Optional if name is already provided above
              # Use global pe creds
              <<: *pe_creds
              # Over-ride global eula config
              eula:
                username: username
                company_name: Nutanix
                job_title: title
              # Use global pulse config
              <<: *pulse
              # Over-ride global ad config
              directory_services:
                directory_type: ACTIVE_DIRECTORY # only ACTIVE_DIRECTORY is supported, port 389 will be used for LDAP
                ad_name: some-other-name
                ad_domain: eng.company.com
                ad_server_ip: valid-ip
                service_account_username: username
                service_account_password: password
                role_mappings:
                  - role_type: ROLE_USER_ADMIN # one of 'ROLE_CLUSTER_ADMIN', 'ROLE_USER_ADMIN', 'ROLE_CLUSTER_VIEWER', 'ROLE_BACKUP_ADMIN'
                    entity_type: GROUP # one of GROUP, OU, USER
                    values:
                      - yash
                      - naveen
              dsip: valid-ip
              networks:
                # Use global network config and add another network
                - <<: *pe_networks
                - name: "vlan-200"
                  subnet_type: VLAN # only VLAN is supported yet
                  vlan_id: 200
                  network_ip: valid-ip
                  network_prefix: 24
                  default_gateway_ip: valid-ip
                  # comment pool_list section if there are no pools for the subnet
                  pool_list:
                    - range: "valid-ip-start valid-ip-end" # Eg "10.10.10.31 10.10.10.40"
                  #  comment dhcp_options section if you don't want dhcp. Over-riding dhcp is not supported yet
                  dhcp_options:
                    domain_name_server_list: [ 10.10.10.10 ]
                    domain_search_list: [ eng.company.com ]
                    domain_name: eng.company.com
              containers:
                # Use global storage container config and add another container
                - <<: *pe_container
                - name: Automation-container-2
                  # All these below parameters are optional
                  #storage_pool_uuid: uuid # Which storage pool to use, comment it to auto pick storage pool
                  reserved_in_gb: 1 # Represents the minimum exclusively reserved storage capacity available for the storage container
                  advertisedCapacity_in_gb: 1 # Represents the maximum storage capacity available for the storage container to use
                  replication_factor: 2 # Number of data copies to maintain
                  compression_enabled: true # Only Inline compression is supported yet
                  compression_delay_in_secs: 0
                  erasure_code: "OFF" # OFF/ ON # Erasure code requires a minimum of 4 nodes when using RF2 and a minimum of 6 nodes when using RF3
                  on_disk_dedup: "OFF" # OFF/ ON # Deduplication is not supported with fewer than 3 nodes
                  nfsWhitelistAddress: [ ] # Access list for storage container

              # The subnets, users that need to be added to NCM project that are created for every cluster
              <<: *ncm_subnets
              <<: *ncm_users

              # NTP, DNS servers
              <<: *ntp_servers
              <<: *name_servers
